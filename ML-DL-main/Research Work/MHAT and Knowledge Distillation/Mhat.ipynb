{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MHAT Integration with Knowledge Distillation"
      ],
      "metadata": {
        "id": "B0QB9HkaFOg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXLxA-q7NqIM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ryPlMkhe1N2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, server, client):\n",
        "        super().__init__()\n",
        "        self.client = client\n",
        "        self.server = server\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        server_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.server_loss_fn = server_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of client\n",
        "        client_predictions = self.client(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of server\n",
        "            server_predictions = self.server(x, training=False)\n",
        "\n",
        "            # Compute losses\n",
        "            server_loss = self.server_loss_fn(y, server_predictions)\n",
        "\n",
        "            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n",
        "            # The magnitudes of the gradients produced by the soft targets scale\n",
        "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
        "            distillation_loss = (\n",
        "                self.distillation_loss_fn(\n",
        "                    tf.nn.softmax(client_predictions / self.temperature, axis=1),\n",
        "                    tf.nn.softmax(server_predictions / self.temperature, axis=1),\n",
        "                )\n",
        "                * self.temperature**2\n",
        "            )\n",
        "\n",
        "            loss = self.alpha * server_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.server.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, server_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"server_loss\": server_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.server(x, training=False)\n",
        "        y_train= y_prediction\n",
        "\n",
        "        # Calculate the loss\n",
        "        server_loss = self.server_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"server_loss\": server_loss})\n",
        "        return results"
      ],
      "metadata": {
        "id": "Wf5GRri4N1k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the client\n",
        "client = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(10, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"client\",\n",
        ")\n",
        "\n",
        "# Create the server\n",
        "server = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(1, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"server\",\n",
        ")\n",
        "\n",
        "# Clone server for later comparison\n",
        "server_scratch = keras.models.clone_model(server)\n",
        "server_scratch1 = keras.models.clone_model(server)"
      ],
      "metadata": {
        "id": "tBZSUI04N7ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the train and test dataset.\n",
        "batch_size = 64\n",
        "(x_train1, y_train1), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train=x_train1[0:1000]\n",
        "y_train=y_train1[0:1000]\n",
        "# Normalize data\n",
        "x_train1 = x_train1.astype(\"float32\") / 255.0\n",
        "x_train1 = np.reshape(x_train1, (-1, 28, 28, 1))\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "dk7f1K0FOAJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3a2b27-591a-4a74-f4fd-92ea39f2f3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train client as usual\n",
        "client.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate client on data.\n",
        "client.fit(x_train1, y_train1, epochs=5)\n",
        "client.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMaZ0iC3ODXN",
        "outputId": "10c6abcd-3e14-429a-f746-8102668f366e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 24s 6ms/step - loss: 0.1831 - sparse_categorical_accuracy: 0.9445\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9705\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9736\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9773\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9791\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9758\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07770504802465439, 0.9757999777793884]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize and compile distiller\n",
        "# distiller = Distiller(server=server, client=client)\n",
        "# distiller.compile(\n",
        "#     optimizer=keras.optimizers.Adam(),\n",
        "#     metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "#     server_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "#     alpha=0.1,\n",
        "#     temperature=10,\n",
        "# )\n",
        "\n",
        "# # Distill client to server\n",
        "# distiller.fit(x_train, y_train, epochs=3)\n",
        "# # y_train=server.predict(x_train)\n",
        "# # print(y_train)\n",
        "# # Evaluate server on test dataset\n",
        "# distiller.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "VzCXIRIOOHAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# tp=client(x_train, training=False)\n",
        "# ff=tf.nn.softmax(tp / 3, axis=1)\n",
        "# print(ff)\n"
      ],
      "metadata": {
        "id": "0JJR0ASVcaze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlX4gy-pd2i7",
        "outputId": "8d6ac99a-0ac4-4042-f6a8-78d31f4f0058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train server as doen usually\n",
        "server_scratch.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate server trained from scratch.\n",
        "server_scratch.fit(x_train1, y_train1, epochs=5)\n",
        "server_scratch.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "qt19sxrfOUxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada51889-78bf-4cf6-e4e7-f423e7eea94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4402 - sparse_categorical_accuracy: 0.8667\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3146 - sparse_categorical_accuracy: 0.9053\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2988 - sparse_categorical_accuracy: 0.9111\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2917 - sparse_categorical_accuracy: 0.9136\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2870 - sparse_categorical_accuracy: 0.9145\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2696 - sparse_categorical_accuracy: 0.9235\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2695508897304535, 0.9235000014305115]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = Distiller(server=server, client=client)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    server_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.995,\n",
        "    temperature=1,\n",
        "  )"
      ],
      "metadata": {
        "id": "OFOvXF0lRu1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller1 = Distiller(server=client, client=server)\n",
        "distiller1.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "      server_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "      alpha=0.01,\n",
        "      temperature=10,\n",
        "  )\n"
      ],
      "metadata": {
        "id": "cKowxxPTRvsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "  # Initialize and compile distiller\n",
        "\n",
        "\n",
        "  # Distill client to server\n",
        "  distiller.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "  # Evaluate server on test dataset\n",
        "  distiller.evaluate(x_test, y_test)\n",
        "  # Initialize and compile distiller\n",
        "\n",
        "  # Distill client to server\n",
        "  distiller1.fit(x_train, y_train, epochs=1)\n",
        "\n",
        "  # Evaluate server on test dataset\n",
        "  distiller1.evaluate(x_test, y_test)\n",
        "  print(\"---------------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-C0BdkBU1sh",
        "outputId": "e74dead7-8ca8-4262-b099-6bbe891ae56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 5s 11ms/step - sparse_categorical_accuracy: 0.4470 - server_loss: 2.1432 - distillation_loss: 2.1017\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.6320 - server_loss: 1.6032 - distillation_loss: 1.5586\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.7360 - server_loss: 0.9861 - distillation_loss: 0.9400\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.7870 - server_loss: 0.7307 - distillation_loss: 0.6818\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.8100 - server_loss: 0.5947 - distillation_loss: 0.5465\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.7694 - server_loss: 0.6892\n",
            "32/32 [==============================] - 1s 6ms/step - sparse_categorical_accuracy: 0.9540 - server_loss: 0.1799 - distillation_loss: 6.6876\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9127 - server_loss: 0.3399\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8350 - server_loss: 0.5489 - distillation_loss: 0.5830\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8480 - server_loss: 0.4821 - distillation_loss: 0.5864\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8580 - server_loss: 0.4439 - distillation_loss: 0.5869\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8640 - server_loss: 0.4267 - distillation_loss: 0.6253\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8780 - server_loss: 0.3886 - distillation_loss: 0.6153\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8203 - server_loss: 0.5445\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9420 - server_loss: 0.2644 - distillation_loss: 2.0579\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9250 - server_loss: 0.2606\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8780 - server_loss: 0.3947 - distillation_loss: 0.3272\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8950 - server_loss: 0.3599 - distillation_loss: 0.3174\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8970 - server_loss: 0.3277 - distillation_loss: 0.3057\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9000 - server_loss: 0.3206 - distillation_loss: 0.3161\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8990 - server_loss: 0.2923 - distillation_loss: 0.3534\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8386 - server_loss: 0.4978\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9540 - server_loss: 0.1794 - distillation_loss: 1.5333\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9327 - server_loss: 0.2191\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9080 - server_loss: 0.3026 - distillation_loss: 0.1868\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9090 - server_loss: 0.2736 - distillation_loss: 0.1914\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9090 - server_loss: 0.2766 - distillation_loss: 0.1929\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 8ms/step - sparse_categorical_accuracy: 0.9200 - server_loss: 0.2531 - distillation_loss: 0.1801\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9150 - server_loss: 0.2617 - distillation_loss: 0.1903\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8373 - server_loss: 0.5179\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9490 - server_loss: 0.1543 - distillation_loss: 1.2991\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9258 - server_loss: 0.2391\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9240 - server_loss: 0.2512 - distillation_loss: 0.1482\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9270 - server_loss: 0.2337 - distillation_loss: 0.1557\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9300 - server_loss: 0.2290 - distillation_loss: 0.1543\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9310 - server_loss: 0.2185 - distillation_loss: 0.1516\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9290 - server_loss: 0.2015 - distillation_loss: 0.1548\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8321 - server_loss: 0.5520\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9510 - server_loss: 0.1463 - distillation_loss: 1.2059\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9132 - server_loss: 0.2729\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9320 - server_loss: 0.1963 - distillation_loss: 0.1174\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9390 - server_loss: 0.1871 - distillation_loss: 0.1236\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9390 - server_loss: 0.1873 - distillation_loss: 0.1550\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9410 - server_loss: 0.1816 - distillation_loss: 0.1258\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9520 - server_loss: 0.1707 - distillation_loss: 0.1405\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8303 - server_loss: 0.5770\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9510 - server_loss: 0.1373 - distillation_loss: 1.0249\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9071 - server_loss: 0.2986\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9430 - server_loss: 0.1652 - distillation_loss: 0.0895\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9480 - server_loss: 0.1705 - distillation_loss: 0.1132\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9460 - server_loss: 0.1668 - distillation_loss: 0.1120\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9460 - server_loss: 0.1631 - distillation_loss: 0.1086\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9440 - server_loss: 0.1652 - distillation_loss: 0.1095\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8132 - server_loss: 0.6736\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9460 - server_loss: 0.1586 - distillation_loss: 0.9512\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8802 - server_loss: 0.3895\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9580 - server_loss: 0.1459 - distillation_loss: 0.1001\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9580 - server_loss: 0.1449 - distillation_loss: 0.1070\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9490 - server_loss: 0.1537 - distillation_loss: 0.1182\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9520 - server_loss: 0.1429 - distillation_loss: 0.1135\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9600 - server_loss: 0.1320 - distillation_loss: 0.1077\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8225 - server_loss: 0.6685\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9570 - server_loss: 0.1442 - distillation_loss: 0.8536\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8841 - server_loss: 0.3923\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9590 - server_loss: 0.1332 - distillation_loss: 0.0817\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9560 - server_loss: 0.1347 - distillation_loss: 0.0779\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9600 - server_loss: 0.1143 - distillation_loss: 0.0774\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9650 - server_loss: 0.1189 - distillation_loss: 0.0725\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9700 - server_loss: 0.1058 - distillation_loss: 0.0696\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8245 - server_loss: 0.7127\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9540 - server_loss: 0.1273 - distillation_loss: 0.7534\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8760 - server_loss: 0.4506\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9670 - server_loss: 0.1032 - distillation_loss: 0.0533\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9710 - server_loss: 0.1139 - distillation_loss: 0.0656\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9620 - server_loss: 0.1234 - distillation_loss: 0.0688\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9690 - server_loss: 0.1000 - distillation_loss: 0.0681\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9740 - server_loss: 0.0961 - distillation_loss: 0.0660\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8221 - server_loss: 0.7527\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9570 - server_loss: 0.1167 - distillation_loss: 0.6715\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8729 - server_loss: 0.4883\n",
            "---------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGZJ60QdHQpf",
        "outputId": "a8e77701-12ce-408c-adc1-246a76d7a2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train server as doen usually\n",
        "server_scratch1.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate server trained from scratch.\n",
        "server_scratch1.fit(x_train, y_train, epochs=5)\n",
        "server_scratch1.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "jrW3Rj9EYh-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6ed402-bea3-4447-9f9f-c4f1f25425f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 1s 4ms/step - loss: 1.8856 - sparse_categorical_accuracy: 0.4880\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.9831 - sparse_categorical_accuracy: 0.7650\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6116 - sparse_categorical_accuracy: 0.8310\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4893 - sparse_categorical_accuracy: 0.8510\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4246 - sparse_categorical_accuracy: 0.8670\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5020 - sparse_categorical_accuracy: 0.8403\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5020046830177307, 0.8403000235557556]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MHAT/Distillation"
      ],
      "metadata": {
        "id": "P1u9UgZ_d19c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, server, client):\n",
        "        super().__init__()\n",
        "        self.client = client\n",
        "        self.server = server\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        server_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.server_loss_fn = server_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of client\n",
        "        client_predictions = self.client(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of server\n",
        "            server_predictions = self.server(x, training=False)\n",
        "\n",
        "            # Compute losses\n",
        "            server_loss = self.server_loss_fn(y, server_predictions)\n",
        "\n",
        "            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n",
        "            # The magnitudes of the gradients produced by the soft targets scale\n",
        "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
        "            distillation_loss = (\n",
        "                self.distillation_loss_fn(\n",
        "                    tf.nn.softmax(client_predictions / self.temperature, axis=1),\n",
        "                    tf.nn.softmax(server_predictions / self.temperature, axis=1),\n",
        "                )\n",
        "                * self.temperature**2\n",
        "            )\n",
        "\n",
        "            loss = self.alpha * server_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.server.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, server_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"server_loss\": server_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.server(x, training=False)\n",
        "        y_train= y_prediction\n",
        "\n",
        "        # Calculate the loss\n",
        "        server_loss = self.server_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"server_loss\": server_loss})\n",
        "        return results"
      ],
      "metadata": {
        "id": "TjbIOslQybqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the client\n",
        "client = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(10, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"client\",\n",
        ")\n",
        "\n",
        "# Create the server\n",
        "server = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(1, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"server\",\n",
        ")\n",
        "\n",
        "# Clone server for later comparison\n",
        "server_scratch = keras.models.clone_model(server)\n",
        "server_scratch1 = keras.models.clone_model(server)"
      ],
      "metadata": {
        "id": "vxqrgwa86vJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the train and test dataset.\n",
        "batch_size = 64\n",
        "(x_train1, y_train1), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train=x_train1[0:1000]\n",
        "y_train=y_train1[0:1000]\n",
        "# Normalize data\n",
        "x_train1 = x_train1.astype(\"float32\") / 255.0\n",
        "x_train1 = np.reshape(x_train1, (-1, 28, 28, 1))\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "-e_ITTBM63b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train client as usual\n",
        "client.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate client on data.\n",
        "client.fit(x_train1, y_train1, epochs=5)\n",
        "client.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Viu8KB64Yw",
        "outputId": "ae806d58-a031-4f20-bb9e-ece3c3db4aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 3ms/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9457\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9741\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9762\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0688 - sparse_categorical_accuracy: 0.9783\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.085181824862957, 0.9743000268936157]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = Distiller(server=server, client=client)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    server_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0,      # 0.955 normal make it 0 for only aggregation result sharing\n",
        "    temperature=5,\n",
        "  )"
      ],
      "metadata": {
        "id": "ybqcEmdC68qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller1 = Distiller(server=client, client=server)\n",
        "distiller1.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "      server_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "      alpha=0,    # 0.01 normal make it 0 for only aggregation result sharing\n",
        "      temperature=10,\n",
        "  )\n"
      ],
      "metadata": {
        "id": "1dRnikY77ELj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "  # Initialize and compile distiller\n",
        "\n",
        "\n",
        "  # Distill client to server\n",
        "  distiller.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "  # Evaluate server on test dataset\n",
        "  distiller.evaluate(x_test, y_test)\n",
        "  # Initialize and compile distiller\n",
        "\n",
        "  # Distill client to server\n",
        "  distiller1.fit(x_train, y_train, epochs=1)\n",
        "\n",
        "  # Evaluate server on test dataset\n",
        "  distiller1.evaluate(x_test, y_test)\n",
        "  print(\"---------------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5jzuxNn7Io-",
        "outputId": "f051d590-a206-42e9-e6c6-a0e6e80e77f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 1s 5ms/step - sparse_categorical_accuracy: 0.1590 - server_loss: 2.1126 - distillation_loss: 28.2752\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.4790 - server_loss: 1.5030 - distillation_loss: 21.3858\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.7180 - server_loss: 0.9256 - distillation_loss: 11.9435\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8030 - server_loss: 0.7580 - distillation_loss: 7.4507\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8380 - server_loss: 0.6398 - distillation_loss: 6.0446\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8219 - server_loss: 0.7807\n",
            "32/32 [==============================] - 2s 7ms/step - sparse_categorical_accuracy: 0.9610 - server_loss: 0.1304 - distillation_loss: 5.5524\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9383 - server_loss: 0.2226\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.8580 - server_loss: 0.5725 - distillation_loss: 1.8873\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8570 - server_loss: 0.5898 - distillation_loss: 1.6547\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8610 - server_loss: 0.5433 - distillation_loss: 1.5042\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8610 - server_loss: 0.6209 - distillation_loss: 1.4686\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8560 - server_loss: 0.5362 - distillation_loss: 1.4116\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8277 - server_loss: 0.6920\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9190 - server_loss: 0.2878 - distillation_loss: 1.5372\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8972 - server_loss: 0.3746\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8670 - server_loss: 0.5081 - distillation_loss: 0.6946\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8560 - server_loss: 0.5265 - distillation_loss: 0.6546\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8590 - server_loss: 0.5284 - distillation_loss: 0.6530\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8560 - server_loss: 0.5299 - distillation_loss: 0.6232\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8570 - server_loss: 0.5317 - distillation_loss: 0.6239\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8301 - server_loss: 0.6980\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9010 - server_loss: 0.3708 - distillation_loss: 0.7650\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8765 - server_loss: 0.4837\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8600 - server_loss: 0.5643 - distillation_loss: 0.4023\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8620 - server_loss: 0.5864 - distillation_loss: 0.3804\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8610 - server_loss: 0.6128 - distillation_loss: 0.3728\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8530 - server_loss: 0.5543 - distillation_loss: 0.3633\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8600 - server_loss: 0.5892 - distillation_loss: 0.3582\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8194 - server_loss: 0.7512\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.8700 - server_loss: 0.4749 - distillation_loss: 0.4797\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8548 - server_loss: 0.5909\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.8460 - server_loss: 0.5975 - distillation_loss: 0.2535\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.8460 - server_loss: 0.6643 - distillation_loss: 0.2477\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.8430 - server_loss: 0.6066 - distillation_loss: 0.2432\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.8440 - server_loss: 0.6078 - distillation_loss: 0.2431\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8430 - server_loss: 0.6135 - distillation_loss: 0.2401\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8135 - server_loss: 0.7913\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8630 - server_loss: 0.5358 - distillation_loss: 0.3375\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8409 - server_loss: 0.6546\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8380 - server_loss: 0.6496 - distillation_loss: 0.1897\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8360 - server_loss: 0.6408 - distillation_loss: 0.1796\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8370 - server_loss: 0.6640 - distillation_loss: 0.1876\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8380 - server_loss: 0.6424 - distillation_loss: 0.1771\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8330 - server_loss: 0.6994 - distillation_loss: 0.1785\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8089 - server_loss: 0.8119\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8530 - server_loss: 0.5755 - distillation_loss: 0.2638\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8365 - server_loss: 0.6646\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8380 - server_loss: 0.6053 - distillation_loss: 0.1530\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8380 - server_loss: 0.6108 - distillation_loss: 0.1421\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8380 - server_loss: 0.6411 - distillation_loss: 0.1440\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8390 - server_loss: 0.6397 - distillation_loss: 0.1419\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8410 - server_loss: 0.7007 - distillation_loss: 0.1430\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8163 - server_loss: 0.7765\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8580 - server_loss: 0.5566 - distillation_loss: 0.2183\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8410 - server_loss: 0.6611\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8530 - server_loss: 0.5807 - distillation_loss: 0.1248\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8530 - server_loss: 0.7482 - distillation_loss: 0.1221\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8510 - server_loss: 0.6302 - distillation_loss: 0.1197\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.8540 - server_loss: 0.5870 - distillation_loss: 0.1141\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.8500 - server_loss: 0.7006 - distillation_loss: 0.1122\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8145 - server_loss: 0.7893\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.8600 - server_loss: 0.5922 - distillation_loss: 0.1827\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8331 - server_loss: 0.7031\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.8500 - server_loss: 0.6300 - distillation_loss: 0.1014\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8510 - server_loss: 0.6319 - distillation_loss: 0.0966\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8510 - server_loss: 0.6417 - distillation_loss: 0.0989\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8520 - server_loss: 0.6444 - distillation_loss: 0.0978\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.8510 - server_loss: 0.6177 - distillation_loss: 0.0973\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8142 - server_loss: 0.7924\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8480 - server_loss: 0.5917 - distillation_loss: 0.1486\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8291 - server_loss: 0.7167\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8480 - server_loss: 0.6231 - distillation_loss: 0.0887\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8450 - server_loss: 0.6107 - distillation_loss: 0.0848\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8420 - server_loss: 0.6219 - distillation_loss: 0.0811\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8410 - server_loss: 0.6015 - distillation_loss: 0.0804\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8450 - server_loss: 0.6105 - distillation_loss: 0.0801\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.8106 - server_loss: 0.8095\n",
            "32/32 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8540 - server_loss: 0.5996 - distillation_loss: 0.1255\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.8252 - server_loss: 0.7376\n",
            "---------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UykGsfVLWpmG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}